---
title: "Statistical power simulations"
author: "Peter Kamerman and Tory Madden"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output: 
    html_document:
        theme: yeti
        highlight: pygments
        df_print: paged
        toc: true
        toc_float: true
        code_folding: show
---

```{r setup, include = FALSE}
# Load packages
library(DHARMa) # GLMM diagnostics
library(ggridges) # Joy plots
library(magrittr)
library(tidyverse)
library(lme4)
library(lmerTest)
library(simr) # Power simulation

# Set knitr options
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE,
                      cache = TRUE,
                      fig.align = 'center',
                      fig.width = 8,
                      fig.height = 8)
```

## Import data
```{r import_data}
df_base <- readr::read_rds('./data/Juliane_raw.rds')
```

## Quick look
```{r quick_look}
dim(df_base)
head(df_base)
glimpse(df_base)
```

## Clean data
```{r clean_data}
df_base %<>%
    # Filter for block_number == test*
    filter(stringr::str_detect(block_number, 'test')) %>%
    # Remove participant 23 (not included in test phase)
    filter(id != 23) %>%
    # Create new columns with stimulus type and block number
    mutate(stimulus = paste0(CS, 'UStest'),
           block_number = ifelse(block_number == 'test1',
                                 yes = 1,
                                 no = ifelse(block_number == 'test2',
                                             yes = 2,
                                             no = 3))) %>%
    # Remove NA
    filter(complete.cases(.)) %>%
    # Recode rating (non-painful < 0, painful > 0)
    mutate(painful = ifelse(rating > 0,
                            yes = 'yes',
                            no = 'no'),
           painful = factor(painful)) %>%
    # Select required columns
    select(id, block_number, trial_number, stimulus, rating, painful)
```

## Plot original data
### Scatter plot
```{r scatter_plot}
df_base %>%
    mutate(id = factor(id),
           painful = factor(painful),
           stimulus = factor(stimulus)) %>%
    ggplot(data = .) +
    aes(x = rating,
        y = id,
        colour = stimulus,
        fill = stimulus) +
    geom_vline(xintercept = 0) +
    geom_jitter(shape = 21,
                alpha = 0.6,
                width = 0) +
    scale_colour_brewer(palette = 'Set1') +
    labs(x = 'FEST rating',
         y = 'Participant ID') +
    theme_minimal(base_size = 14) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank())
```

### Joy plot
```{r joy_plot}
df_base %>%
    mutate(id = factor(id),
           painful = factor(painful),
           stimulus = factor(stimulus)) %>%
    ggplot(data = .) +
    aes(x = rating,
        y = id,
        colour = stimulus,
        fill = stimulus) +
    geom_vline(xintercept = 0) +
    geom_density_ridges() +
    scale_colour_brewer(palette = 'Set1') +
    labs(x = 'FEST rating',
         y = 'Participant ID') +
    theme_minimal(base_size = 14) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank())
```    

## Base model

The `simr` package works with GLMM outputs from the `lme4` package. I therefore compared the outputs from a Cochran-Mantel-Haenszel (CMH) chi-squared test (my prefered test in this case), to that of a GLMM using a _logit_ link. 

### CMH test
```{r cmh_test}
# xtab data
mod_tab <- xtabs(~ painful + stimulus + id, 
                 data = df_base)

# Inspect table
ftable(mod_tab)

# CMH test
mod_cmh <- mantelhaen.test(x = mod_tab,
                           exact = TRUE)

# Pretty print
broom::tidy(mod_cmh) %>%
    knitr::kable(digits = 3,
                 caption = 'CMH test of stimulus rating x stimulus x participant')
```

### Logistic regression
```{r logit_model}
# Create a model using the empirical data
mod_base <- glmer(painful ~ stimulus + (1 | id),
                 data = df_base,
                 family = binomial)

# Summarise model
summary(mod_base)

# Get 95% CI of the fixed effect coefficients (log odds)
confint(mod_base)

# Get 95% CI of the odds ratio for the fixed effect
exp(confint(mod_base))

# Diagnostics of model residuals using simulation (n = 1000)
## Simulate residual distribution
mod_diagnostics <- simulateResiduals(fittedModel = mod_base,
                                     n = 1000)

## Plot residuals 
plotSimulatedResiduals(mod_diagnostics)

## Formal test of residual uniformity 
testUniformity(mod_diagnostics)
```

I was happy with the logistic regression model, and proceeded with the power simulations.

## Power simulations

_"Observed power"_ is problematic, so instead of using the raw data (df_base), I took a random sample (with replacement) of 40 individuals from df_base, and re-build a dummy cohort from this sample.

For the simulation process, I estimated statistical power over a range of sample sizes (5 to 40) over a range of small effect sizes (log odds: 0.1, 0.2, 0.4, 0.6, 0.8, 1.0).

### Create the dummy dataset
```{r create_dataset}
# Set random seed
set.seed(1234)

# Take a sample of df_base
df_pwr <- df_base %>%
    # Group and nest dataframe by id
    group_by(id) %>%
    nest() %>%
    # Take a random sample of n = 40 with replacement
    sample_n(size = 40,
             replace = TRUE) %>%
    # Relabel ids
    mutate(id = 1:40) %>%
    # Unnest dataframe
    unnest() 
```

### Basic logit model
```{r basic_model_2}
# Generate a model using df_pwr
mod_pwr <- glmer(painful ~ stimulus + (1 | id),
                 data = df_pwr,
                 family = binomial)
```


### MODEL 1: effect size: 0.1
```{r model_1}
# Change effect size
fixef(mod_pwr)["stimulusCSplusUStest"] <- 0.1

# Simulate power curve
pwr_curve_0.1 <- powerCurve(fit = mod_pwr, 
                            along = 'id',  
                            seed = 1234,
                            breaks = c(5, 10, 15, 20, 25, 30, 35, 40),
                            progress = FALSE)

# Print
pwr_curve_0.1

# Plot
plot(pwr_curve_0.1)
```

### MODEL 2: effect size: 0.2
```{r model_2}
# Change effect size
fixef(mod_pwr)["stimulusCSplusUStest"] <- 0.2

# Simulate power curve
pwr_curve_0.2 <- powerCurve(fit = mod_pwr, 
                            along = 'id', 
                            seed = 1234,
                            breaks = c(5, 10, 15, 20, 25, 30, 35, 40),
                            progress = FALSE)

# Print
pwr_curve_0.2

# Plot
plot(pwr_curve_0.2)
```

### MODEL 3: effect size: 0.4
```{r model_3}
# Change effect size
fixef(mod_pwr)["stimulusCSplusUStest"] <- 0.4

# Simulate power curve
pwr_curve_0.4 <- powerCurve(fit = mod_pwr, 
                            along = 'id',  
                            seed = 1234,
                            breaks = c(5, 10, 15, 20, 25, 30, 35, 40),
                            progress = FALSE)

# Print
pwr_curve_0.4

# Plot
plot(pwr_curve_0.4)
```

### MODEL 5: effect size: 0.8
```{r model_5}
# Change effect size
fixef(mod_pwr)["stimulusCSplusUStest"] <- 0.8

# Simulate power curve
pwr_curve_0.8 <- powerCurve(fit = mod_pwr, 
                            along = 'id',  
                            seed = 1234,
                            breaks = c(5, 10, 15, 20, 25, 30, 35, 40),
                            progress = FALSE)

# Print
pwr_curve_0.8

# Plot
plot(pwr_curve_0.8)
```

### MODEL 5: effect size: 1.0
```{r model_6}
# Change effect size
fixef(mod_pwr)["stimulusCSplusUStest"] <- 1.0

# Simulate power curve
pwr_curve_1.0 <- powerCurve(fit = mod_pwr, 
                            along = 'id',  
                            seed = 1234,
                            breaks = c(5, 10, 15, 20, 25, 30, 35, 40),
                            progress = FALSE)

# Print
pwr_curve_1.0

# Plot
plot(pwr_curve_1.0)
```

## Session information
```{r session_info}
sessionInfo()
```